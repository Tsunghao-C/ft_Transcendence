networks:
  frontend_net:
    driver: bridge
  backend_net:
    driver: bridge
    # internal: true
    internal: false # in order to send 2FA
  monitoring_net:
    driver: bridge

volumes:
  vault_debian_shared_data:
    name: vault_debian_data
    driver: local
    driver_opts:
      device: ./security/vault_debian/volumes/shared_data
      o: bind
      type: none
  vault_debian_file:
    name: vault_file
    driver: local
    driver_opts:
      device: ./security/vault_debian/volumes/file
      o: bind
      type: none
  static_volume: {} # Added by Ben
  media_data: {} # docker volume for storing pictures
  logs_nginx: {}
  logs_modsec: {}
  redis_data: {}
  game_data: {}
  prometheus_data: {}
  grafana_data: {}
  filebeat_registry: {}
  es_data:
    driver: local
  kibana_certs:
    driver: local

services:
  # Security Layer
  vault_debian:
    container_name: vault_debian
    build:
      context: ./security/vault_debian
      dockerfile: Dockerfile
    cap_add:
      - IPC_LOCK
    ports:
      - "8200:8200"
    environment:
      VAULT_ADDR: "https://127.0.0.1:8200"
      VAULT_API_ADDR: "https://127.0.0.1:8200"
      VAULT_SKIP_VERIFY: "true"
    volumes:
      - vault_debian_shared_data:/vault/shared_data
      - vault_debian_file:/vault/file
    stop_signal: SIGTERM # DTIW

  ## [Alex] to finish WAF later after major modules are tested working

  # waf:
  #   container_name: waf
  #   build:
  #     context: ./security/waf
  #   ports:
  #     - "8443:443"
  #     - "8080:80"
  #   volumes:
  #     - ./security/waf/rules:/etc/modsecurity.d/rules
  #     - ./security/waf/nginx:/etc/nginx/conf.d
  #   depends_on:
  #     nginx:
  #       condition: service_healthy
  #   networks:
  #     - frontend_net
  #   healthcheck:
  #     test: ["CMD", "nginx", "-t"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 3
  #   restart: unless-stopped

  # Frontend Layer
  ## [Theo] & [Alex]
  nginx:
    container_name: nginx
    build:
      context: ./frontend/nginx
      dockerfile: Dockerfile
    volumes:
      - ./frontend/nginx/spa_files:/usr/share/nginx/html
      - static_volume:/app/static:ro
      - logs_nginx:/var/log/nginx
      - logs_modsec:/var/log/modsec
      - media_data:/app/media
    ports:
      - "8443:443"
      - "8080:80"
    networks:
      - frontend_net
      - backend_net
    env_file:
      - .env
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      - django
    healthcheck:
      test: ["CMD", "curl", "-k", "https://localhost:443/health" ]
      interval: 2s
      timeout: 2s
      retries: 1
    restart: unless-stopped

  # User Service
  ## [Ben]

  redis:
    container_name: redis
    image: redis:alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    # ports:
    #   - "6380:6379"     # only for development stage, need to close after
    networks:
      - backend_net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 5
    restart: unless-stopped

  django:
    container_name: django
    build:
      context: ./backend
      dockerfile: Dockerfile
    image: django
    pull_policy: never
    volumes:
      - static_volume:/app/static
      - media_data:/home/app/pong-game/media
    expose:
      - 8004
      - 8001
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - backend_net
    env_file:
      - .env
    restart: unless-stopped

  postgres:
    container_name: postgres
    image: postgres:14-alpine
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASS}
      - POSTGRES_PORT=5434
    # ports:
    #   - "5434:5434"  # Map the container port to the host
    command: postgres -p 5434
    volumes:
      - game_data:/var/lib/postgresql/data
      - media_data:/app/media
    networks:
      - backend_net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB} -h localhost -p 5434 || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Monitoring Stack
  # prometheus:
  #   container_name: prometheus
  #   image: prom/prometheus
  #   user: "1000:1000"
  #   ports:
  #     - "9090:9090"   # only for development stage
  #   volumes:
  #     - ./monitoring/prometheus:/etc/prometheus
  #     - prometheus_data:/prometheus
  #   networks:
  #     - monitoring_net
  #   restart: unless-stopped

  # grafana:
  #   container_name: grafana
  #   image: grafana/grafana
  #   user: "1000:1000"
  #   ports:
  #     - "3001:3001"
  #   environment:
  #     - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
  #   volumes:
  #     - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
  #     - grafana_data:/var/lib/grafana
  #   networks:
  #     - monitoring_net
  #   restart: unless-stopped

  # cadvisor:
  #   container_name: cadvisor
  #   image: gcr.io/cadvisor/cadvisor
  #   user: "1000:1000"
  #   volumes:
  #     - /:/rootfs:ro
  #     - /var/run:/var/run:rw
  #     - /sys:/sys:ro
  #     - /var/lib/docker/:/var/lib/docker:ro
  #   networks:
  #     - monitoring_net
  #   restart: unless-stopped

  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    environment:
      # Cluster configuration
      - node.name=es01
      - cluster.name=pong-game-logs
      - discovery.type=single-node
      - network.host=0.0.0.0
      # Basic settings
      - bootstrap.memory_lock=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      # Disk allocation setting
      - "cluster.routing.allocation.disk.threshold_enabled=true"
      - "cluster.routing.allocation.disk.watermark.low=85%"
      - "cluster.routing.allocation.disk.watermark.high=90%"
      - "cluster.routing.allocation.disk.watermark.flood_stage=95%"
      # Security settings (Admin user)
      - xpack.security.enabled=true
      - xpack.security.authc.api_key.enabled=true
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      # Transport SSL settings
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=/usr/share/elasticsearch/config/certs/elastic-transport.key
      - xpack.security.transport.ssl.certificate=/usr/share/elasticsearch/config/certs/elastic-transport.crt
      - xpack.security.transport.ssl.certificate_authorities=/usr/share/elasticsearch/config/certs/ca.crt
      # HTTP SSL settings
      - xpack.security.http.ssl.enabled=true
      - xpack.security.http.ssl.key=/usr/share/elasticsearch/config/certs/elastic-http.key
      - xpack.security.http.ssl.certificate=/usr/share/elasticsearch/config/certs/elastic-http.crt
      - xpack.security.http.ssl.certificate_authorities=/usr/share/elasticsearch/config/certs/ca.crt
    volumes:
      - ./monitoring/elk/certs:/usr/share/elasticsearch/config/certs:ro
      - es_data:/usr/share/elasticsearch/data
      - ./monitoring/elk/elasticsearch/setup:/setup
    entrypoint: >
      sh -c '
        /usr/local/bin/docker-entrypoint.sh &
        ELASTIC_PID=$!
        sleep 15 &&
        /setup/init.sh &
        wait $ELASTIC_PID'
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    networks:
      - monitoring_net
    healthcheck:
      test: ["CMD-SHELL", "curl -k -s https://localhost:9200/_cat/health || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  kibana:
    container_name: kibana
    image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
    volumes:
      - ./monitoring/elk/certs:/usr/share/kibana/config/certs:ro
      - ./monitoring/elk/kibana/dashboards:/usr/share/kibana/dashboards
      - ./monitoring/elk/kibana/setup:/usr/share/kibana/setup
    ports:
      - "5601:5601" # Only external access point for ELK
    environment:
      # Elasticsearch connection
      - ELASTICSEARCH_HOSTS=https://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=kibana_system
      - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=/usr/share/kibana/config/certs/ca.crt
      - ELASTICSEARCH_SSL_VERIFICATIONMODE=certificate
      # Server settings
      - SERVER_HOST=0.0.0.0
      - SERVER_NAME=kibana
      # Security settings
      - XPACK_SECURITY_ENABLED=true
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${KIBANA_ENCRYPTION_KEY}
      # Performance settings
      - ELASTICSEARCH_REQUESTTIMEOUT=90000  # Added timeout
      - OPTIMIZATION_PROFILING=false
      # Other settings
      - TELEMETRY_ENABLED=false
      # TLS related settings
      - SERVER_SSL_ENABLED=true
      - SERVER_SSL_CERTIFICATE=/usr/share/kibana/config/certs/kibana.crt
      - SERVER_SSL_KEY=/usr/share/kibana/config/certs/kibana.key
      - SERVER_SSL_REDIRECT=true
    networks:
      - monitoring_net
    depends_on:
      elasticsearch:
        condition: service_healthy
    # healthcheck:
    #   test: ["CMD-SHELL", "curl -s -I -u kibana_system:${ELASTIC_PASSWORD} http://localhost:5601/api/status | grep -q '200 OK'"]
    #   interval: 20s
    #   timeout: 10s
    #   retries: 3
    entrypoint: >
      sh -c '
        /usr/share/kibana/setup/import-dashboards.sh &
        /usr/local/bin/kibana-docker'
    restart: unless-stopped

  logstash:
    container_name: logstash
    image: docker.elastic.co/logstash/logstash:${STACK_VERSION}
    volumes:
      - ./monitoring/elk/certs:/usr/share/logstash/config/certs:ro
      - ./monitoring/elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:rw
      - ./monitoring/elk/logstash/pipeline:/usr/share/logstash/pipeline:ro
    environment:
      - LS_JAVA_OPTS=-Xmx256m -Xms256m
      - ELASTIC_USER=${ELASTIC_USER}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      # SSL / TLS setting
      - XPACK_MONITORING_ELASTICSEARCH_HOSTS=https://elasticsearch:9200
      - XPACK_MONITORING_ELASTICSEARCH_USERNAME=${ELASTIC_USER}
      - XPACK_MONITORING_ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD}
      - XPACK_MONITROING_ELASTICSEARCH_SSL_CERTIFICATE_AUTHORITY=/usr/share/logstash/config/certs/ca.crt
    networks:
      - monitoring_net
    depends_on:
      elasticsearch:
        condition: service_healthy
    # healthcheck:
    #   test: ["CMD", "curl", "-f", "http://localhost:9600"]
    #   interval: 10s
    #   timeout: 10s
    #   retries: 3
    restart: unless-stopped

  filebeat:
    container_name: filebeat
    image: docker.elastic.co/beats/filebeat:${STACK_VERSION}
    user: root  # Required to read logs
    volumes:
      - ./monitoring/elk/certs:/usr/share/filebeat/certs:ro
      - ./monitoring/elk/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml
      # Mount all log directories
      - logs_nginx:/var/log/nginx
      - logs_modsec:/var/log/modsec
      - filebeat_registry:/usr/share/filebeat/data
    environment:
      - ELASTIC_USER=${ELASTIC_USER}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
    entrypoint: >
      sh -c '
      chmod go-w /usr/share/filebeat/filebeat.yml &&
      filebeat -e --strict.perms=false'
    networks:
      - monitoring_net
      - frontend_net
    depends_on:
      - logstash
        # condition: service_healthy